{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import utils\n",
    "\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "#sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils to show Tensor Image\n",
    "unloader = transforms.ToPILImage()\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    image = image.squeeze(0)      # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colorizationDataset(Dataset):\n",
    "    def __init__(self, root=None, tf=None):\n",
    "        self.tf = tf\n",
    "        self.grey = np.load(\"./image-colorization/gray_scale.npy\") # get your numpy array paths here\n",
    "        self.grey = torch.from_numpy(self.grey)\n",
    "        \n",
    "        self.color = np.load(\"./image-colorization/ab/ab1.npy\")\n",
    "        self.color = np.concatenate((self.color,np.load(\"./image-colorization/ab/ab2.npy\")))\n",
    "        self.color = np.concatenate((self.color,np.load(\"./image-colorization/ab/ab3.npy\")))\n",
    "        self.color = torch.from_numpy(self.color)\n",
    "        \n",
    "        #self.transformations(tf)\n",
    "        #print(self.images.shape)\n",
    "        #self.images = self.toPyTensor()\n",
    "        #print(self.images.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.tf is None:\n",
    "            self.tf = transforms.ToTensor()\n",
    "        return (self.grey[index]),(self.color[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grey)\n",
    "    \n",
    "    def transformations(self,tf=None):\n",
    "        if self.tf is None:\n",
    "            self.tf = transforms.ToTensor()\n",
    "        \n",
    "        self.grey = self.tf(self.grey)\n",
    "        self.color = self.tf(self.color)\n",
    "        \n",
    "#         return tf(self.grey)\n",
    "\n",
    "img_size = 224\n",
    "# Create Dataset of grey-colored images\n",
    "#tf = transforms.Compose([transforms.ToPILImage(mode=\"LAB\"),\n",
    "#                         transforms.Resize(img_size),\n",
    "#                         transforms.ToTensor()])\n",
    "dataset = colorizationDataset(tf=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Stats\n",
    "grey, color = dataset[0]\n",
    "print(\"Dataset Length: \", len(dataset))\n",
    "print(\"Each grayscale image is size: \", grey.shape)\n",
    "print(\"Each color image is size: \", color.shape)\n",
    "print(\"Image data type: \", grey.dtype , grey.device)\n",
    "print(\"Sample image:\", grey)\n",
    "plt.title(\"Grey\")\n",
    "plt.imshow(grey.squeeze(), cmap=\"gray\")\n",
    "\n",
    "# Recreating RGB image using the L and AB from the dataset\n",
    "\n",
    "\n",
    "def toRGB(grey,color):\n",
    "    # Initializing with zeros ( or any random number)\n",
    "    img = np.zeros((img_size, img_size, 3))\n",
    "    img[:, :, 0] = grey\n",
    "    img[:, :, 1:] = color.permute(1,2,0)\n",
    "    img = img.astype('uint8')\n",
    "    img_ = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n",
    "    return img_\n",
    "\n",
    "# Convert to RGB Space to plot it\n",
    "plt.figure()\n",
    "plt.title(\"Colored\")\n",
    "img_ = toRGB(grey,color)\n",
    "plt.imshow(img_)\n",
    "print(type(img_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show a batch\n",
    "def show_images_batch(sample_batched):\n",
    "    \"\"\"Show image for a batch of samples.\"\"\"\n",
    "    greys_batch, color_batch = \\\n",
    "            sample_batched[0], sample_batched[1]\n",
    "    \n",
    "    batch_size = len(greys_batch)\n",
    "    #print(batch_size)\n",
    "    im_size = greys_batch.size(2)\n",
    "    #print(im_size)\n",
    "    grid_border_size = 2\n",
    "\n",
    "    greys_batch = greys_batch.unsqueeze(3)\n",
    "    print(\"Greys batch: \",greys_batch.shape)\n",
    "    print(\"Color batch: \",color_batch.shape)\n",
    "    \n",
    "    combined = torch.cat((greys_batch,color_batch),3)\n",
    "    print(\"Combined: \", combined.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    grid = utils.make_grid(greys_batch.permute(0,3,1,2))\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    plt.title('Grey Batch from dataloader')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    colored = []\n",
    "    for i in range(batch_size):\n",
    "        colored.append(torch.from_numpy( cv2.cvtColor(combined[i].numpy().astype('uint8'), cv2.COLOR_LAB2RGB) ) )\n",
    "\n",
    "    # Combine list of Tensor into a single Tensor\n",
    "    color = torch.stack(colored)\n",
    "    print(\"Color Stack: \", type(color), color.shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    grid2 = utils.make_grid(color.permute(0,3,1,2))\n",
    "    plt.imshow(grid2.numpy().transpose(1,2,0))\n",
    "    plt.title('Colored Batch from dataloader')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "   \n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "   # print(i_batch, sample_batched[0].shape,\n",
    "     #     sample_batched[1].shape)\n",
    "    \n",
    "    # observe 1th batch and stop.\n",
    "    if i_batch == 2:\n",
    "        print(\"Batch: \",i_batch)\n",
    "        \n",
    "        #plt.figure()\n",
    "        show_images_batch(sample_batched)\n",
    "        #plt.axis('off')\n",
    "        #plt.ioff()\n",
    "        #plt.show()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 2*img_size*img_size\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "def images_to_vectors(images,channels):\n",
    "    return images.view(images.size(0),channels*img_size*img_size)\n",
    "\n",
    "def vectors_to_images(vectors,channels):\n",
    "    return vectors.view(vectors.size(0), channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = img_size*img_size\n",
    "        n_out = 2*img_size*img_size\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Number of steps to apply to the discriminator\n",
    "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
    "# Number of epochs\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = torch.ones(size, 1)\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = torch.zeros(size, 1)\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, sample_batch in enumerate(dataloader):\n",
    "        #show_images_batch(sample_batch)\n",
    "        \n",
    "        real_batch_grey = sample_batch[0]\n",
    "        real_batch_color = sample_batch[1]\n",
    "        \n",
    "        #print(real_batch_grey)\n",
    "        #v = images_to_vectors(real_batch_grey,1)\n",
    "        #print(\"V: \",v)\n",
    "        \n",
    "        # 1. Train Discriminator\n",
    "        real_data_grey = real_batch_grey.view(real_batch_grey.size(0),-1)#images_to_vectors(real_batch_grey,1)\n",
    "        real_data_color = real_batch_color.view(real_batch_color.size(0),-1)#images_to_vectors(real_batch_color,2)\n",
    "\n",
    "        print(real_data_grey.shape)\n",
    "        print(real_data_color.shape)\n",
    "        \n",
    "        if torch.cuda.is_available(): real_data_grey = real_data_grey.cuda()\n",
    "        if torch.cuda.is_available(): real_data_color = real_data_color.cuda()\n",
    "                \n",
    "        # Generate fake data\n",
    "        fake_data_color = generator(real_data_grey.float()) #noise(real_data.size(0))).detach()\n",
    "        \n",
    "        #print(real_data_grey.shape)\n",
    "        #print(real_data_color.dtype)\n",
    "        \n",
    "        #print(vectors_to_images(real_data_grey,1).shape)\n",
    "        #print(vectors_to_images(real_data_color,2).shape)\n",
    "\n",
    "        #img = np.zeros((img_size, img_size, 3))\n",
    "        #img[:, :, 0] = real_data_grey.view(real_data_grey.size(0),img_size,img_size).cpu()[0]# vectors_to_images(real_data_grey,1)[0].cpu().unsqueeze(0)\n",
    "        #img[:, :, 1:] = real_data_color.view(real_data_color.size(0),img_size,img_size,2).cpu()[0] #vectors_to_images(real_data_color,2)[0].cpu().permute(1,2,0)\n",
    "        #img = img.astype('uint8')\n",
    "        #img_ = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)        \n",
    "        #plt.figure()\n",
    "        #plt.imshow(img_)\n",
    "\n",
    "        \n",
    "        fakepicture = torch.cat((real_data_grey.view(real_data_grey.size(0),img_size,img_size,1),fake_data_color.view(real_data_color.size(0),img_size,img_size,2).type(torch.uint8)),3)\n",
    "        #images = vectors_to_images(fakepicture,3).cpu()\n",
    "        print(fakepicture.shape)\n",
    "\n",
    "        grey = fakepicture[:,:,:,0]\n",
    "        print(\"Grey:\",grey.shape)\n",
    "        #plt.imshow(grey.cpu())\n",
    "        \n",
    "        color = fakepicture[:,:,:,1:]\n",
    "        print(\"Color:\",color.shape)\n",
    "\n",
    "        #im = toRGB(grey.cpu(),color.cpu())\n",
    "        #plt.imshow(im)\n",
    "        \n",
    "        \n",
    "        generated = (grey.cpu(),color.cpu())\n",
    "        show_images_batch(generated)\n",
    "        \n",
    "        \n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
    "                                                                real_data_color.float(), fake_data_color.float())\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(real_data_grey.float())\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        # Log error\n",
    "        #logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "\n",
    "        # Display Progress\n",
    "        if (n_batch) % 100 == 0:\n",
    "            display.clear_output(True)\n",
    "            # Display Images\n",
    "            test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
    "            #logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
    "            # Display status Logs\n",
    "            #logger.display_status(\n",
    "            #    epoch, num_epochs, n_batch, num_batches,\n",
    "            #    d_error, g_error, d_pred_real, d_pred_fake\n",
    "            #)\n",
    "        # Model Checkpoints\n",
    "        #logger.save_models(generator, discriminator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "##############################\n",
    "#           U-NET\n",
    "##############################\n",
    "\n",
    "\n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128)\n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)\n",
    "\n",
    "\n",
    "##############################\n",
    "#        Discriminator\n",
    "##############################\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        # Concatenate image and condition image by channels to produce input\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = img_size\n",
    "        self.img_cols = img_size\n",
    "        self.in_channels = 1\n",
    "        self.out_channels = 3\n",
    "        \n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.in_channels)\n",
    "\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "    \n",
    "        self.optimizer = optim.Adam(self.generator.parameters(), lr=0.0002,betas=(0.5,0.99))\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = nn.Sequential(nn.Linear(256,512),\n",
    "                              nn.LeakyReLU(negative_slope=0.2),\n",
    "                              nn.BatchNorm2d(512),\n",
    "                              nn.Linear(512,1024),\n",
    "                              nn.LeakyReLU(negative_slope=0.2),\n",
    "                              nn.BatchNorm2d(1024),\n",
    "                              nn.Linear(1024,np.prod(self.img_shape)),\n",
    "                              nn.LeakyReLU(negative_slope=0.2),\n",
    "                              nn.BatchNorm2d(np.prod(self.img_shape)),\n",
    "                              nn.Linear(np.prod(self.img_shape)),\n",
    "                              nn.TanH()\n",
    "                              \n",
    "                             )\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
